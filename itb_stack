#! /usr/bin/python3
# -*- coding: utf-8 -*-

# Copyright (c) 2025 Mikio Hirabayashi
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.


import argparse
import logging
import os
import re
import shutil
import subprocess
import sys
import tempfile
import time

import cv2
import numpy as np


PROG_NAME = "itb_combine"
PROG_VERSION = "0.0.1"
CMD_EXIFTOOL = "exiftool"
CMD_HUGIN_ALIGN = "align_image_stack"


logging.basicConfig(format="%(message)s", stream=sys.stderr)
logger = logging.getLogger(PROG_NAME)
logger.setLevel(logging.INFO)
cmd_env = os.environ
cmd_env["PATH"] = cmd_env["PATH"] + ":/opt/homebrew/bin"
cmd_env["PATH"] = cmd_env["PATH"] + ":/usr/local/bin"
cmd_env["PATH"] = cmd_env["PATH"] + ":/Applications/Hugin/tools_mac"
cv2.setLogLevel(0)


def has_command(name):
  """Checks existence of a command."""
  return bool(shutil.which(name))


def load_image(file_path):
  """Loads an image and return its linear RGB data as a NumPy array."""
  logger.debug(f"loading {file_path}")
  image = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)
  if image is None:
    raise ValueError(f"Failed to load {file_path}")
  if image.dtype == np.uint32:
    image = image.astype(np.float32) / float((1<<32) - 1)
    bits = 32
  elif image.dtype == np.uint16:
    image = image.astype(np.float32) / float((1<<16) - 1)
    bits = 16
  else:
    image = image.astype(np.float32) / float((1<<8) - 1)
    bits = 8
  if len(image.shape) == 2:
    image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
  elif image.shape[2] == 4:
    image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)
  h, w = image.shape[:2]
  logger.debug(f"h={h}, w={w}, area={h*w}, bits={bits}")
  image = srgb_to_linear(image)
  return image, bits


def save_image(file_path, image, bits):
  """Saves an image after converting it from linear RGB to sRGB."""
  logger.debug(f"saving {file_path}")
  image = linear_to_srgb(image)
  ext = os.path.splitext(file_path)[1].lower()
  if ext in ['.jpg', '.jpeg']:
    image = (np.clip(image, 0, 1) * ((1<<8) - 1)).astype(np.uint8)
  elif ext in ['.png', '.tiff', '.tif']:
    if bits == 32:
      image = (np.clip(image, 0, 1) * ((1<<32) - 1)).astype(np.uint32)
    elif bits == 16:
      image = (np.clip(image, 0, 1) * ((1<<16) - 1)).astype(np.uint16)
    else:
      image = (np.clip(image, 0, 1) * ((1<<8) - 1)).astype(np.uint8)
  else:
    raise ValueError(f"Unsupported file format: {ext}")
  success = cv2.imwrite(file_path, image)
  if not success:
    raise ValueError(f"Failed to save image: {file_path}")


def copy_metadata(source_path, target_path):
  """Copies EXIF data and ICC profile from source image to target image."""
  cmd = ["exiftool", "-TagsFromFile", source_path, "-icc_profile",
         "-thumbnailimage=", "-f", "-m", "-overwrite_original", target_path]
  logger.debug(f"running: {' '.join(cmd)}")
  subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL,
                 stderr=subprocess.DEVNULL)


def srgb_to_linear(image):
  """Converts sRGB to linear RGB using OpenCV (optimized for float32)."""
  image = np.where(image <= 0.04045,
                   image / 12.92, cv2.pow((image + 0.055) / 1.055, 2.4))
  return image.astype(np.float32)


def linear_to_srgb(image):
  """Converts linear RGB to sRGB using OpenCV (optimized for float32)."""
  image = np.where(image <= 0.0031308,
                   image * 12.92, 1.055 * cv2.pow(image, 1/2.4) - 0.055)
  return image.astype(np.float32)


def compute_brightness(image):
  """Computes the average brightness of an image in grayscale."""
  return np.mean(cv2.cvtColor(image.astype(np.float32), cv2.COLOR_BGR2GRAY))


def lighten_image(image, factor):
  """Lightens the image by applying a scaled log transformation."""
  image = np.log1p(image * factor) / np.log1p(factor)
  return image.astype(np.float32)


def darken_image(image, factor):
  """Darkens the image by applying an inverse log transformation."""
  image = (np.expm1(image * np.log1p(factor))) / factor
  return image.astype(np.float32)


def naive_sigmoid(x, gain, mid):
  """Computes naive sigmod conversion."""
  image = 1.0 / (1.0 + np.exp((mid - x) * gain))
  return image.astype(np.float32)


def naive_inverse_sigmoid(x, gain, mid):
  """Computes inverse naive sigmoid conversion."""
  min_val = naive_sigmoid(0.0, gain, mid)
  max_val = naive_sigmoid(1.0, gain, mid)
  a = (max_val - min_val) * x + min_val
  return -np.log(1.0 / a - 1.0) / gain


def sigmoidal_contrast(image, gain, mid):
  """Applies sigmoidal contrast adjustment with a scaled sigmoid function."""
  min_val = naive_sigmoid(0.0, gain, mid)
  max_val = naive_sigmoid(1.0, gain, mid)
  diff = max_val - min_val
  return np.clip((naive_sigmoid(image, gain, mid) - min_val) / diff,
                 0, 1).astype(np.float32)


def inverse_sigmoidal_contrast(image, gain, mid):
  """Applies inverse sigmoidal contrast adjustment."""
  min_val = naive_inverse_sigmoid(0.0, gain, mid)
  max_val = naive_inverse_sigmoid(1.0, gain, mid)
  diff = max_val - min_val
  return np.clip((naive_inverse_sigmoid(
    image, gain, mid) - min_val) / diff, 0, 1).astype(np.float32)


def adjust_exposure(image, target_brightness):
  """Adjusts the exposure of an image to a target brightness."""
  num_tries = 0
  leverage = 1.0
  brightness = compute_brightness(image)
  while num_tries < 10:
    num_tries += 1
    if (brightness == 0 or target_brightness == 0 or
        brightness == target_brightness):
      break
    dist = abs(np.log(target_brightness / brightness))
    logger.debug(f"tries={num_tries}, dist={dist:.3f},"
                 f" brightness={brightness:.3f}")
    if dist < 0.1:
      break
    if brightness <= target_brightness:
      factor = np.expm1(target_brightness * np.log1p(brightness)) / brightness
      factor = max(leverage, factor)
      adjusted_image = lighten_image(image, factor)
    else:
      factor = np.expm1(np.log1p(target_brightness) / brightness)
      factor = max(leverage, factor)
      adjusted_image = darken_image(image, factor)
    adjusted_brightness = compute_brightness(adjusted_image)
    adjusted_dist = abs(np.log(target_brightness / adjusted_brightness))
    if adjusted_dist < dist:
      image = adjusted_image
      brightness = adjusted_brightness
    leverage *= 0.5
  return image


def align_images(images):
  """Aligns images using OpenCV."""
  if len(images) < 2:
    return images
  ref_image = images[0]
  h, w = ref_image.shape[:2]
  orb = cv2.ORB_create(nfeatures=5000)
  ref_gray = cv2.cvtColor(ref_image, cv2.COLOR_BGR2GRAY)
  ref_gray = (np.clip(ref_gray, 0, 1) * 255).astype(np.uint8)
  ref_kp, ref_des = orb.detectAndCompute(ref_gray, None)
  if ref_des is None:
    logger.debug(f"reference image has no descriptors")
    return images
  aligned_images = [ref_image]
  bounding_boxes = []
  for image in images[1:]:
    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    image_gray = (np.clip(image_gray, 0, 1) * 255).astype(np.uint8)
    kp, des = orb.detectAndCompute(image_gray, None)
    if des is None:
      logger.debug(f"image has no descriptors")
      aligned_images.append(image)
      continue
    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    matches = bf.match(ref_des, des)
    matches = sorted(matches, key=lambda x: x.distance)
    if len(matches) > 10:
      logger.debug(f"matches={len(matches)}")
      src_pts = np.float32([ref_kp[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)
      dst_pts = np.float32([kp[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)
      m, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)
      if m is not None:
        logger.debug(f"warping: m={m}, w={w}, h={h}")
        aligned_image = cv2.warpPerspective(image, m, (w, h))
        aligned_images.append(aligned_image)
        corners = np.float32([[0, 0], [w, 0], [w, h], [0, h]]).reshape(-1, 1, 2)
        transformed_corners = cv2.perspectiveTransform(corners, m)
        x_min, y_min = np.min(transformed_corners, axis=0).flatten()
        x_max, y_max = np.max(transformed_corners, axis=0).flatten()
        bounding_boxes.append((int(x_min), int(y_min), int(x_max), int(y_max)))
      else:
        logger.debug(f"no homography")
        aligned_images.append(image)
    else:
      logger.debug(f"no matches")
      aligned_images.append(image)
  if bounding_boxes:
    x_min = max(b[0] for b in bounding_boxes)
    y_min = max(b[1] for b in bounding_boxes)
    x_max = min(b[2] for b in bounding_boxes)
    y_max = min(b[3] for b in bounding_boxes)
    if x_min != 0 or y_min != 0 or x_max != w or y_max != h:
      crop_w = x_max - x_min
      crop_h = y_max - y_min
      aspect_ratio = w / h
      cropped_aspect_ratio = crop_w / crop_h
      if cropped_aspect_ratio > aspect_ratio * 1.001:
        new_crop_w = int(crop_h * aspect_ratio)
        x_min = x_min + (crop_w - new_crop_w) // 2
        x_max = x_min + new_crop_w
      elif cropped_aspect_ratio < aspect_ratio * 0.999:
        new_crop_h = int(crop_w / aspect_ratio)
        y_min = y_min + (crop_h - new_crop_h) // 2
        y_max = y_min + new_crop_h
      logger.debug(f"cropping: x_min={x_min}, y_min={y_min}, x_max={x_max}, y_max={y_max}")
      cropped_images = [img[y_min:y_max, x_min:x_max] for img in aligned_images]
    else:
      logger.debug(f"no need to crop")
      cropped_images = aligned_images
  else:
    logger.debug(f"no need to crop")
    cropped_images = aligned_images
  return cropped_images


def align_images_hugin(images, input_paths, bits_list):
  """Aligns images using Hugin."""
  if len(images) < 2:
    return images
  temp_dir = tempfile.gettempdir()
  pid = os.getpid()
  tmp_paths = []
  prefix = f"itb_stack-{pid:08d}"
  full_prefix = os.path.join(temp_dir, prefix)
  cmd = [CMD_HUGIN_ALIGN, "-C", "-c", "64", "-a", f"{full_prefix}-output-"]
  align_input_paths = []
  for image, input_path, bits in zip(images, input_paths, bits_list):
    ext = os.path.splitext(input_path)[1].lower()
    align_input_path = f"{full_prefix}-input-{len(align_input_paths)+1:04d}{ext}"
    align_input_paths.append(align_input_path)
    save_image(align_input_path, image, bits)
    cmd.append(align_input_path)
  logger.debug(f"running: {' '.join(cmd)}")
  subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
  for align_input_path in align_input_paths:
    os.remove(align_input_path)
  aligned_images = []
  for name in os.listdir(temp_dir):
    if not name.startswith(prefix): continue
    align_output_path = os.path.join(temp_dir, name)
    image, bits = load_image(align_output_path)
    aligned_images.append(image)
    os.remove(align_output_path)
  return aligned_images


def merge_images_average(images):
  """Merges images by average composition."""
  return np.mean(images, axis=0)


def merge_images_debevec(images):
  """Merges images by Debevec HDR method."""
  brightness_values = np.array([compute_brightness(image) for image in images])
  exposures = brightness_values / max(np.min(brightness_values), 0.001)
  byte_images = [(np.clip(image, 0, 1) * 255).astype(np.uint8)
                 for image in images]
  merger = cv2.createMergeDebevec()
  hdr = merger.process(byte_images, times=exposures)
  return hdr


def merge_images_robertson(images):
  """Merges images by Robertson HDR method."""
  brightness_values = np.array([compute_brightness(image) for image in images])
  exposures = brightness_values / max(np.min(brightness_values), 0.001)
  byte_images = [(np.clip(image, 0, 1) * 255).astype(np.uint8)
                 for image in images]
  merger = cv2.createMergeRobertson()
  hdr = merger.process(byte_images, times=exposures)
  return hdr


def merge_images_mertens(images):
  """Merges images by Mertens HDR method."""
  byte_images = [(np.clip(image, 0, 1) * 255).astype(np.uint8)
                 for image in images]
  merger = cv2.createMergeMertens()
  hdr = merger.process(byte_images)
  return hdr


def tone_map_image_linear(image):
  """Applies tone mapping by linear normalization."""
  return cv2.normalize(image, None, 0, 1, cv2.NORM_MINMAX).astype(np.float32)


def tone_map_image_reinhard(image):
  """Applies tone mapping by Reinhard method."""
  tonemap = cv2.createTonemapReinhard(gamma=1.0, intensity=0, light_adapt=0.5,
                                      color_adapt=0.5)
  ldr = np.clip(tonemap.process(image), 0, 1)
  return ldr


def tone_map_image_drago(image):
  """Applies tone mapping by Drago method."""
  tonemap = cv2.createTonemapDrago(gamma=1.0, saturation=1.0, bias=0.9)
  ldr = np.clip(tonemap.process(image), 0, 1)
  return ldr


def tone_map_image_mantiuk(image):
  """Applies tone mapping by Mantiuk method."""
  tonemap = cv2.createTonemapMantiuk(gamma=1.0, scale=0.9, saturation=1.0)
  ldr = np.clip(tonemap.process(image), 0, 1)
  return ldr


def write_caption(capexpr, image):
  """Write a text on an image."""
  h, w = image.shape[:2]
  fields = capexpr.split("|")
  text = fields[0]
  font = cv2.FONT_HERSHEY_SIMPLEX
  font_ratio = 1.0
  if len(fields) > 1:
    match = re.fullmatch(r" *(\d+\.\d*) *", fields[1])
    if match:
      font_ratio = float(match.group(1))
  font_scale = 0.01 * np.sqrt(h * w) / 5 * font_ratio
  thickness = max(1, int(font_scale))
  r, g, b = (255, 255, 255)
  if len(fields) > 2:
    match = re.fullmatch(r" *#?([0-9a-fA-F]{3,6}) *", fields[2])
    if match:
      expr = match.group(1)
      if len(expr) == 3:
        (r, g, b) = (int(expr[0] * 2, 16), int(expr[1] * 2, 16), int(expr[2] * 2, 16))
      elif len(expr) == 6:
        (r, g, b) = (int(expr[0:2], 16), int(expr[2:4], 16), int(expr[4:6], 16))
  r, g, b = float(r) / 255, float(g) / 255, float(b) / 255
  font_color = (b, g, r)
  line_type = cv2.LINE_AA
  tw, th = cv2.getTextSize(text, font, font_scale, thickness)[0]
  tx = (w - tw) // 2
  ty = (h + th) // 2
  if len(fields) > 3:
    match = re.fullmatch(r" *([a-xA-X]+) *", fields[3])
    if match:
      expr = match.group(1).lower()
      if "t" in expr:
        ty = th + h // 40
      elif "b" in expr:
        ty = h - h // 40
      if "l" in expr:
        tx = w // 50
      if "r" in expr:
        tx = w - tw - w // 40
  logger.debug(f"text={text}, scale={font_scale:.2f},"
               f" r={r:.2f}, g={g:.2f}, b={b:.2f},"
               f" x={tx}, y={ty}, w={tw}, h={th}")
  cv2.putText(image, text, (tx, ty), font, font_scale, font_color, thickness, line_type)
  return image


def main():
  """Execute all operations."""
  description = "Stack and combine images."
  epilog = f"{PROG_NAME} version {PROG_VERSION}. Powered by OpenCV2."
  ap = argparse.ArgumentParser(
    prog=PROG_NAME, description=description, epilog=epilog,
    formatter_class=argparse.RawDescriptionHelpFormatter)
  ap.add_argument("images", nargs='+', help="input image paths")
  ap.add_argument("--output", "-o", default="output.tif", metavar="path",
                  help="output image path (dafault=output.tif)")
  ap.add_argument("--average-input-exposure", "-ax", action='store_true',
                  help="average input exposure")
  ap.add_argument("--align", action='store_true',
                  help="Align input images before merging")
  ap.add_argument("--align-hugin", action='store_true',
                  help="Use Hugin to align input images before merging")
  ap.add_argument("--merge-method", "-mm", default="average", metavar="name",
                  help="Choose a processing method:"
                  " average (default), debevec, robertson, mertens")
  ap.add_argument("--tone-method", "-tm", default="linear", metavar="name",
                  help="Choose a tone mapping method dor debevec:"
                  " linear (default), reinhard, drago, mantiuk")
  ap.add_argument("--no-restore", "-nr", action='store_true',
                  help="do not apply auto restoration of brightness")
  ap.add_argument("--slog", type=float, default=0, metavar="num",
            help="scaled log brightness adjustment."
            " positive to lighten, negative to darken")
  ap.add_argument("--sigmoid", type=float, default=0, metavar="num",
            help="sigmoidal contrast adjustment."
            " positive to strengthen, negative to weaken")
  ap.add_argument("--caption", default="", metavar="text",
                  help="put a caption text: TEXT|SIZE|COLOR|POS"
                  " eg. Hello|5|ddeeff|tl")
  ap.add_argument("--debug", action='store_true', help="print debug messages")
  args = ap.parse_args()
  start_time = time.time()
  if args.debug:
    logger.setLevel(logging.DEBUG)
  logger.debug(f"{PROG_NAME}={PROG_VERSION},"
               " OpenCV={cv2.__version__}, NumPy={np.__version__}")
  logger.info(f"Process started: input={args.images}, output={args.output}")
  logger.info(f"Loading the input files")
  images_data = [load_image(input_path) for input_path in args.images]
  images, bits_list = zip(*images_data)
  brightness_values = np.array([compute_brightness(image) for image in images])
  mean_brightness = np.mean(brightness_values)
  logger.debug(f"mean_brightness={mean_brightness:.3f}")
  if args.average_input_exposure:
    logger.info(f"Adjusting input exposure to the mean")
    images = [adjust_exposure(image, mean_brightness) for image in images]
  if args.align_hugin and has_command(CMD_HUGIN_ALIGN):
    logger.info(f"Aligning images by {CMD_HUGIN_ALIGN}")
    images = align_images_hugin(images, args.images, bits_list)
  elif args.align:
    logger.info(f"Aligning images")
    images = align_images(images)
  is_hdr = False
  if args.merge_method in ["average", "a"]:
    logger.info(f"Merging images by average composition")
    merged_image = merge_images_average(images)
  elif args.merge_method in ["debevec", "d"]:
    logger.info(f"Merging images by Debevec method as an HDRI")
    merged_image = merge_images_debevec(images)
    is_hdr = True
  elif args.merge_method in ["robertson", "r"]:
    logger.info(f"Merging images by Robertson method")
    merged_image = merge_images_robertson(images)
  elif args.merge_method in ["mertens", "m"]:
    logger.info(f"Merging images by Mertens method")
    merged_image = merge_images_mertens(images)
  else:
    raise ValueError(f"Unknown merge method")
  if is_hdr:
    if args.tone_method in ["linear", "l"]:
      logger.info(f"Tone mapping images by linear reduction")
      merged_image = tone_map_image_linear(merged_image)
    elif args.tone_method in ["reinhard", "r"]:
      logger.info(f"Tone mapping images by Reinhard method")
      merged_image = tone_map_image_reinhard(merged_image)
    elif args.tone_method in ["drago", "d"]:
      logger.info(f"Tone mapping images by Drago method")
      merged_image = tone_map_image_drago(merged_image)
    elif args.tone_method in ["mantiuk", "m"]:
      logger.info(f"Tone mapping images by Mantiuk method")
      merged_image = tone_map_image_mantiuk(merged_image)
    else:
      raise ValueError(f"Unknown tone method")
  if not args.no_restore:
    logger.info(f"Applying auto restoration of brightness")
    merged_image = adjust_exposure(merged_image, mean_brightness)
  if args.slog > 0:
    merged_image = lighten_image(merged_image, args.slog)
  elif args.slog < 0:
    merged_image = darken_image(merged_image, -args.slog)
  if args.sigmoid > 0:
    merged_image = sigmoidal_contrast(merged_image, args.sigmoid, 0.5)
  elif args.sigmoid < 0:
    merged_image = inverse_sigmoidal_contrast(merged_image, -args.sigmoid, 0.5)
  if len(args.caption) > 0:
    logger.info(f"Writing the caption")
    merged_image = write_caption(args.caption, merged_image)
  logger.info(f"Saving the output file")
  save_image(args.output, merged_image, bits_list[0])
  if has_command(CMD_EXIFTOOL):
    logger.info(f"Copying metadata")
    copy_metadata(args.images[0], args.output)
  elapsed_time = time.time() - start_time
  logger.info(f"Process done: time={elapsed_time:.2f}s")


if __name__ == "__main__":
  main()
